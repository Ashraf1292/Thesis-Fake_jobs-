{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOnaBM8cNxEXjYIJlIKwT/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8e4abca61504d25bf579a6da0b35370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feea7193a22a444bb223ebe52fc71bda",
              "IPY_MODEL_9adefb8e65244f71baa59196009cc65b",
              "IPY_MODEL_a9ef267ffae34835b8f14ee7471cac76"
            ],
            "layout": "IPY_MODEL_80e2f46dedfa434f96ea9bd7ee9da680"
          }
        },
        "feea7193a22a444bb223ebe52fc71bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a32235db6a04ae884b7e06787c6ffd8",
            "placeholder": "​",
            "style": "IPY_MODEL_d31f0e305c5240a4b0a934b821f68288",
            "value": "100%"
          }
        },
        "9adefb8e65244f71baa59196009cc65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d9a7510fc94829811f0c559745933c",
            "max": 17880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0058c65fca6546f4b2c41e4f6f9b3fda",
            "value": 17880
          }
        },
        "a9ef267ffae34835b8f14ee7471cac76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1d44bddf944aedbfb91c35dbd35c6d",
            "placeholder": "​",
            "style": "IPY_MODEL_815fcfa43efb49bd83c76eade2516dd9",
            "value": " 17880/17880 [00:10&lt;00:00, 2573.56it/s]"
          }
        },
        "80e2f46dedfa434f96ea9bd7ee9da680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a32235db6a04ae884b7e06787c6ffd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31f0e305c5240a4b0a934b821f68288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d9a7510fc94829811f0c559745933c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0058c65fca6546f4b2c41e4f6f9b3fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec1d44bddf944aedbfb91c35dbd35c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "815fcfa43efb49bd83c76eade2516dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b88ac7ab31c42ac906353d3f9e77e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa222ba4e6914f6582aaaebcfa98fdb5",
              "IPY_MODEL_89041a8df12742aa9aea2729d77578e6",
              "IPY_MODEL_0e6db437c559439eaf3cefc2293bf52a"
            ],
            "layout": "IPY_MODEL_873febfee4fd42cdbc213c20cb94fd0b"
          }
        },
        "fa222ba4e6914f6582aaaebcfa98fdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc72acd235ae448080111deba988c6af",
            "placeholder": "​",
            "style": "IPY_MODEL_42c756be128d487682da66198fbbd1cc",
            "value": "100%"
          }
        },
        "89041a8df12742aa9aea2729d77578e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a5e20af91cf439db6dfbe09208d647f",
            "max": 17880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baf0da53249e485dab49814afa318181",
            "value": 17880
          }
        },
        "0e6db437c559439eaf3cefc2293bf52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82352b71d7e0413fbad815b634251910",
            "placeholder": "​",
            "style": "IPY_MODEL_be161783aa324e368886f9a00a6ba57a",
            "value": " 17880/17880 [00:04&lt;00:00, 4009.71it/s]"
          }
        },
        "873febfee4fd42cdbc213c20cb94fd0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc72acd235ae448080111deba988c6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c756be128d487682da66198fbbd1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a5e20af91cf439db6dfbe09208d647f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf0da53249e485dab49814afa318181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82352b71d7e0413fbad815b634251910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be161783aa324e368886f9a00a6ba57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashraf1292/Thesis-Fake_jobs-/blob/main/grok_version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU7xKinyNazm",
        "outputId": "4ddfc29f-dadf-4d14-c0de-c801072c00e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q nltk scikit-learn xgboost transformers shap tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"Please upload your dataset file (emscad_dataset.csv)...\")\n",
        "data = pd.read_csv('fake_job_postings.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(f\"Dataset loaded with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
        "print(f\"Number of fraudulent jobs: {data['fraudulent'].sum()}\")\n",
        "print(f\"Percentage of fraudulent jobs: {data['fraudulent'].mean()*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAxDOuREOhsS",
        "outputId": "5687fdf9-d4f1-4630-81e2-416ea42aac61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your dataset file (emscad_dataset.csv)...\n",
            "Dataset loaded with 17880 rows and 18 columns\n",
            "Number of fraudulent jobs: 866\n",
            "Percentage of fraudulent jobs: 4.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Text Preprocessing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Download required NLTK resources with error handling\n",
        "try:\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "    print(\"NLTK resources downloaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading NLTK resources: {e}\")\n",
        "    # Alternative download method with SSL context\n",
        "    import ssl\n",
        "    try:\n",
        "        _create_unverified_https_context = ssl._create_unverified_context\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    else:\n",
        "        ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text by removing URLs, special characters, and normalizing.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert to lowercase and strip whitespace\n",
        "    text = text.lower().strip()\n",
        "\n",
        "    # Simple word splitting instead of nltk tokenize to avoid potential issues\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Handle NaN values\n",
        "data['description'] = data['description'].fillna('')\n",
        "data['company_profile'] = data['company_profile'].fillna('')\n",
        "\n",
        "# Apply text cleaning with progress tracking\n",
        "print(\"Cleaning job descriptions...\")\n",
        "tqdm.pandas()\n",
        "data['clean_description'] = data['description'].progress_apply(clean_text)\n",
        "print(\"Cleaning company profiles...\")\n",
        "data['clean_company_profile'] = data['company_profile'].progress_apply(clean_text)\n",
        "print(\"Text cleaning completed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "d8e4abca61504d25bf579a6da0b35370",
            "feea7193a22a444bb223ebe52fc71bda",
            "9adefb8e65244f71baa59196009cc65b",
            "a9ef267ffae34835b8f14ee7471cac76",
            "80e2f46dedfa434f96ea9bd7ee9da680",
            "6a32235db6a04ae884b7e06787c6ffd8",
            "d31f0e305c5240a4b0a934b821f68288",
            "a5d9a7510fc94829811f0c559745933c",
            "0058c65fca6546f4b2c41e4f6f9b3fda",
            "ec1d44bddf944aedbfb91c35dbd35c6d",
            "815fcfa43efb49bd83c76eade2516dd9",
            "1b88ac7ab31c42ac906353d3f9e77e6b",
            "fa222ba4e6914f6582aaaebcfa98fdb5",
            "89041a8df12742aa9aea2729d77578e6",
            "0e6db437c559439eaf3cefc2293bf52a",
            "873febfee4fd42cdbc213c20cb94fd0b",
            "fc72acd235ae448080111deba988c6af",
            "42c756be128d487682da66198fbbd1cc",
            "1a5e20af91cf439db6dfbe09208d647f",
            "baf0da53249e485dab49814afa318181",
            "82352b71d7e0413fbad815b634251910",
            "be161783aa324e368886f9a00a6ba57a"
          ]
        },
        "id": "KmOpiRdTPmt_",
        "outputId": "5b6c7b7d-93f6-4b72-8ed0-9ddcb0e25a6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK resources downloaded successfully\n",
            "Cleaning job descriptions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17880 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8e4abca61504d25bf579a6da0b35370"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning company profiles...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17880 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b88ac7ab31c42ac906353d3f9e77e6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text cleaning completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XnludNE1R_oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Metadata Feature Engineering\n",
        "def profile_completeness(profile):\n",
        "    \"\"\"Calculate completeness of company profile.\"\"\"\n",
        "    if not isinstance(profile, str) or len(profile.strip()) == 0:\n",
        "        return 0.0\n",
        "    return min(1.0, len(profile.split()) / 100.0)  # Normalize and cap at 1.0\n",
        "\n",
        "data['profile_completeness'] = data['company_profile'].apply(profile_completeness)\n",
        "\n",
        "# Industry fraud likelihood (based on training data)\n",
        "industry_fraud_rate = data.groupby('industry')['fraudulent'].mean().to_dict()\n",
        "data['industry_fraud_likelihood'] = data['industry'].map(industry_fraud_rate).fillna(0.0)\n"
      ],
      "metadata": {
        "id": "lCIcmaDEQBcl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Feature Extraction\n",
        "import numpy as np\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "print(\"Extracting TF-IDF features...\")\n",
        "# TF-IDF for description and company profile\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "tfidf_desc = tfidf_vectorizer.fit_transform(data['clean_description'])\n",
        "tfidf_profile = tfidf_vectorizer.transform(data['clean_company_profile'])\n",
        "print(f\"TF-IDF features extracted: {tfidf_desc.shape[1]} features\")\n",
        "\n",
        "# Check for available accelerators\n",
        "use_gpu = tf.test.is_gpu_available() if hasattr(tf.test, 'is_gpu_available') else len(tf.config.list_physical_devices('GPU')) > 0\n",
        "use_tpu = False\n",
        "\n",
        "# Try to initialize TPU if available\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    use_tpu = True\n",
        "    print(f\"Running on TPU: {tpu.master()}\")\n",
        "except ValueError:\n",
        "    # Fall back to GPU or CPU\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print(f\"TPU not available. Running on {'GPU' if use_gpu else 'CPU'}\")\n",
        "\n",
        "# Set BERT usage flag based on available hardware\n",
        "use_bert = use_tpu or use_gpu  # Only use BERT if TPU or GPU is available\n",
        "bert_embeddings = None\n",
        "\n",
        "if use_bert:\n",
        "    print(\"Using BERT for feature extraction\")\n",
        "    from transformers import AutoTokenizer, TFAutoModel\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    def get_bert_embeddings(texts, batch_size=16, max_length=128):\n",
        "        \"\"\"Generate DistilBERT embeddings with memory management and progress tracking.\"\"\"\n",
        "        embeddings = []\n",
        "        total_batches = (len(texts) // batch_size) + (1 if len(texts) % batch_size else 0)\n",
        "\n",
        "        # Create dataset for batching\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(texts).batch(batch_size)\n",
        "\n",
        "        with strategy.scope():\n",
        "            model = TFAutoModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "        for i, batch_texts in enumerate(dataset):\n",
        "            if i % 10 == 0:  # Print every 10 batches\n",
        "                print(f\"Processing BERT batch {i + 1}/{total_batches}\")\n",
        "\n",
        "            batch_texts = [text.decode('utf-8') if isinstance(text, bytes) else text\n",
        "                         for text in batch_texts.numpy()]\n",
        "\n",
        "            # Handle empty texts to prevent tokenizer errors\n",
        "            batch_texts = [text if text.strip() else \"empty\" for text in batch_texts]\n",
        "\n",
        "            try:\n",
        "                inputs = tokenizer(batch_texts, return_tensors='tf', max_length=max_length,\n",
        "                                  truncation=True, padding=True)\n",
        "                outputs = model(inputs)\n",
        "                batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "                embeddings.append(batch_embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"Error in batch {i}: {e}\")\n",
        "                # Create zero embeddings as fallback\n",
        "                batch_embeddings = np.zeros((len(batch_texts), model.config.dim))\n",
        "                embeddings.append(batch_embeddings)\n",
        "\n",
        "            # Clear memory\n",
        "            if i % 20 == 0:  # Every 20 batches\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "\n",
        "        all_embeddings = np.vstack(embeddings)\n",
        "\n",
        "        # Dimensionality reduction\n",
        "        print(\"Performing PCA to reduce BERT dimensions...\")\n",
        "        pca = PCA(n_components=min(100, all_embeddings.shape[0], all_embeddings.shape[1]))\n",
        "        reduced_embeddings = pca.fit_transform(all_embeddings)\n",
        "        print(f\"Reduced BERT embeddings from {all_embeddings.shape[1]} to {reduced_embeddings.shape[1]} dimensions\")\n",
        "\n",
        "        return reduced_embeddings\n",
        "\n",
        "    try:\n",
        "        # Get DistilBERT embeddings\n",
        "        bert_embeddings = get_bert_embeddings(data['clean_description'].tolist(),\n",
        "                                             batch_size=16 if use_tpu else 8,\n",
        "                                             max_length=128)\n",
        "\n",
        "        # Save embeddings to disk for future use\n",
        "        import pickle\n",
        "        with open('bert_embeddings.pkl', 'wb') as f:\n",
        "            pickle.dump(bert_embeddings, f)\n",
        "        print(\"BERT embeddings saved to disk\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating BERT embeddings: {e}\")\n",
        "        print(\"Proceeding without BERT features\")\n",
        "        use_bert = False\n",
        "        bert_embeddings = None\n",
        "else:\n",
        "    print(\"Skipping BERT feature extraction (no TPU/GPU available)\")\n",
        "\n",
        "# Combine features\n",
        "print(\"Combining features...\")\n",
        "metadata_features = csr_matrix(data[['profile_completeness', 'industry_fraud_likelihood']].values)\n",
        "\n",
        "if use_bert and bert_embeddings is not None:\n",
        "    bert_sparse = csr_matrix(bert_embeddings)\n",
        "    combined_features = hstack([tfidf_desc, tfidf_profile, bert_sparse, metadata_features])\n",
        "    print(f\"Combined features with BERT: {combined_features.shape}\")\n",
        "else:\n",
        "    combined_features = hstack([tfidf_desc, tfidf_profile, metadata_features])\n",
        "    print(f\"Combined features without BERT: {combined_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vzz4PrCSFjW",
        "outputId": "ea9e06ea-a7a3-4283-9eb8-1ce57640d8de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting TF-IDF features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-178f1512cfa8>:16: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF features extracted: 5000 features\n",
            "TPU not available. Running on CPU\n",
            "Skipping BERT feature extraction (no TPU/GPU available)\n",
            "Combining features...\n",
            "Combined features without BERT: (17880, 10002)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6EtSquRS3XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uRQYtSmvS-Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    combined_features, data['fraudulent'],\n",
        "    test_size=0.2, stratify=data['fraudulent'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqkiE06JSOke",
        "outputId": "5a00c4e0-9587-4742-a2a7-552ce98bcf98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 14304 samples\n",
            "Test set: 3576 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Model Training\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Calculate class weight based on data\n",
        "pos_weight = (y_train.shape[0] - y_train.sum()) / y_train.sum()\n",
        "print(f\"Positive class weight: {pos_weight:.2f}\")\n",
        "\n",
        "# Base models with proper parameters\n",
        "print(\"Training individual models...\")\n",
        "lr_model = LogisticRegression(\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    solver='liblinear',  # Better for imbalanced data\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    scale_pos_weight=pos_weight,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Random Forest can be computationally expensive - skip if too slow\n",
        "use_rf = True\n",
        "try:\n",
        "    rf_model = RandomForestClassifier(\n",
        "        class_weight='balanced',\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        max_depth=10  # Limit depth for faster training\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error with Random Forest: {e}\")\n",
        "    use_rf = False\n",
        "\n",
        "# Train base models\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr_model.fit(X_train, y_train)\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "if use_rf:\n",
        "    print(\"Training Random Forest...\")\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Stacked Ensemble\n",
        "print(\"Creating ensemble model...\")\n",
        "if use_rf:\n",
        "    ensemble_model = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', lr_model),\n",
        "            ('xgb', xgb_model),\n",
        "            ('rf', rf_model)\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "else:\n",
        "    ensemble_model = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', lr_model),\n",
        "            ('xgb', xgb_model)\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "\n",
        "# Train ensemble\n",
        "print(\"Training ensemble model...\")\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Threshold optimization\n",
        "print(\"Optimizing decision threshold...\")\n",
        "y_scores = ensemble_model.predict_proba(X_test)[:, 1]\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "optimal_idx = np.argmax(f1_scores[:-1])  # Skip last element (threshold=1.0)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal threshold: {optimal_threshold:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7wpfMKSjk0",
        "outputId": "f0921672-54ae-4687-f91b-5f922398d703"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive class weight: 19.64\n",
            "Training individual models...\n",
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [13:44:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "Creating ensemble model...\n",
            "Training ensemble model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [13:45:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing decision threshold...\n",
            "Optimal threshold: 0.6680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluation\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Function to print metrics as percentages\n",
        "def print_metrics_as_percentage(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    precision = precision_score(y_true, y_pred) * 100\n",
        "    recall = recall_score(y_true, y_pred) * 100\n",
        "    f1 = f1_score(y_true, y_pred) * 100\n",
        "\n",
        "    print(f\"\\n{model_name} Performance Metrics (%):\")\n",
        "    print(f\"Accuracy:  {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall:    {recall:.2f}%\")\n",
        "    print(f\"F1 Score:  {f1:.2f}%\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Predict with optimal threshold\n",
        "y_pred_ensemble = (ensemble_model.predict_proba(X_test)[:, 1] >= optimal_threshold).astype(int)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_rf = rf_model.predict(X_test) if use_rf else None\n",
        "\n",
        "# Evaluate all models\n",
        "print(\"\\n=== MODEL EVALUATIONS ===\")\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "lr_metrics = print_metrics_as_percentage(y_test, y_pred_lr, \"Logistic Regression\")\n",
        "\n",
        "print(\"\\nXGBoost Results:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "xgb_metrics = print_metrics_as_percentage(y_test, y_pred_xgb, \"XGBoost\")\n",
        "\n",
        "if use_rf:\n",
        "    print(\"\\nRandom Forest Results:\")\n",
        "    print(classification_report(y_test, y_pred_rf))\n",
        "    rf_metrics = print_metrics_as_percentage(y_test, y_pred_rf, \"Random Forest\")\n",
        "\n",
        "print(\"\\nStacked Ensemble Results with Optimized Threshold:\")\n",
        "print(classification_report(y_test, y_pred_ensemble))\n",
        "ensemble_metrics = print_metrics_as_percentage(y_test, y_pred_ensemble, \"Ensemble (optimized)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SMKccrjTCGq",
        "outputId": "20adc19f-2a0c-400a-9ccc-c32452ac80f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MODEL EVALUATIONS ===\n",
            "\n",
            "Logistic Regression Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98      3403\n",
            "           1       0.59      0.92      0.72       173\n",
            "\n",
            "    accuracy                           0.97      3576\n",
            "   macro avg       0.79      0.95      0.85      3576\n",
            "weighted avg       0.98      0.97      0.97      3576\n",
            "\n",
            "\n",
            "Logistic Regression Performance Metrics (%):\n",
            "Accuracy:  96.53%\n",
            "Precision: 59.04%\n",
            "Recall:    92.49%\n",
            "F1 Score:  72.07%\n",
            "\n",
            "XGBoost Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      3403\n",
            "           1       0.74      0.83      0.78       173\n",
            "\n",
            "    accuracy                           0.98      3576\n",
            "   macro avg       0.86      0.91      0.88      3576\n",
            "weighted avg       0.98      0.98      0.98      3576\n",
            "\n",
            "\n",
            "XGBoost Performance Metrics (%):\n",
            "Accuracy:  97.73%\n",
            "Precision: 73.71%\n",
            "Recall:    82.66%\n",
            "F1 Score:  77.93%\n",
            "\n",
            "Random Forest Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.93      3403\n",
            "           1       0.27      0.96      0.42       173\n",
            "\n",
            "    accuracy                           0.87      3576\n",
            "   macro avg       0.63      0.91      0.67      3576\n",
            "weighted avg       0.96      0.87      0.90      3576\n",
            "\n",
            "\n",
            "Random Forest Performance Metrics (%):\n",
            "Accuracy:  86.94%\n",
            "Precision: 26.52%\n",
            "Recall:    95.95%\n",
            "F1 Score:  41.55%\n",
            "\n",
            "Stacked Ensemble Results with Optimized Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      3403\n",
            "           1       0.89      0.81      0.85       173\n",
            "\n",
            "    accuracy                           0.99      3576\n",
            "   macro avg       0.94      0.90      0.92      3576\n",
            "weighted avg       0.99      0.99      0.99      3576\n",
            "\n",
            "\n",
            "Ensemble (optimized) Performance Metrics (%):\n",
            "Accuracy:  98.57%\n",
            "Precision: 88.61%\n",
            "Recall:    80.92%\n",
            "F1 Score:  84.59%\n"
          ]
        }
      ]
    }
  ]
}